{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09951eda-2f80-4dfa-bad8-d6926eab0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73083f-4a68-4dbd-aaa9-6be6f80297e8",
   "metadata": {},
   "source": [
    "# Helper function for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5257780-0b2a-48bb-b81c-c4415d1534b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, y_scores=None):\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    if y_scores is not None:\n",
    "        avg_precision = average_precision_score(y_true, y_scores)\n",
    "        print(f\"Average Precision (AUC-PR): {avg_precision:.4f}\")\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    return avg_precision, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47132565-8c0e-4dc0-823c-081fa699b30c",
   "metadata": {},
   "source": [
    "# Prepare and train models for a datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed7e10e0-cedd-4516-9fa7-7ca8942839bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X, y, dataset_name=\"Dataset\"):\n",
    "    print(f\"\\n=== {dataset_name} ===\")\n",
    "    # Train-test split with stratification to keep imbalance ratio\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    # Scale numeric features (important for logistic regression)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Handle imbalance with SMOTE (if you have it), else comment this and train on original\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    # Logistic Regression\n",
    "    logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    logreg.fit(X_train_res, y_train_res)\n",
    "    y_pred_logreg = logreg.predict(X_test_scaled)\n",
    "    y_score_logreg = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    print(\"\\nLogistic Regression Performance:\")\n",
    "    evaluate_model(y_test, y_pred_logreg, y_score_logreg)\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train_res, y_train_res)\n",
    "    y_pred_rf = rf.predict(X_test_scaled)\n",
    "    y_score_rf = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    print(\"\\nRandom Forest Performance:\")\n",
    "    evaluate_model(y_test, y_pred_rf, y_score_rf)\n",
    "\n",
    "    # Determine \"best\" model by Average Precision and F1-score\n",
    "    ap_logreg, f1_logreg = evaluate_model(y_test, y_pred_logreg, y_score_logreg)\n",
    "    ap_rf, f1_rf = evaluate_model(y_test, y_pred_rf, y_score_rf)\n",
    "\n",
    "    if ap_rf > ap_logreg and f1_rf > f1_logreg:\n",
    "        print(\"\\n=> Random Forest is the best model based on AUC-PR and F1-score.\")\n",
    "    else:\n",
    "        print(\"\\n=> Logistic Regression is the best model based on AUC-PR and F1-score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d816719d-e6d3-47b6-9522-c1ad0ba7b76d",
   "metadata": {},
   "source": [
    "# For Fraud_Data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "056efab5-06f4-498a-86aa-cfda0cddd9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Task 1: Data Loading, Merging, Feature Engineering --------\n",
    "\n",
    "def to_ip_int(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(ipaddress.ip_address(val))\n",
    "    except:\n",
    "        try:\n",
    "            return int(float(val))\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "def task1_prepare_fraud_data(fraud_path, ip_path):\n",
    "    fraud_df = pd.read_csv('../data/Fraud_Data.csv')\n",
    "    ip_df = pd.read_csv('../data/IpAddress_to_Country.csv')\n",
    "\n",
    "    fraud_df['ip_int'] = fraud_df['ip_address'].apply(to_ip_int)\n",
    "    ip_df['lower'] = ip_df['lower_bound_ip_address'].apply(to_ip_int)\n",
    "    ip_df['upper'] = ip_df['upper_bound_ip_address'].apply(to_ip_int)\n",
    "\n",
    "    fraud_df = fraud_df.dropna(subset=['ip_int'])\n",
    "    ip_df = ip_df.dropna(subset=['lower'])\n",
    "\n",
    "    fraud_df = fraud_df.sort_values('ip_int').reset_index(drop=True)\n",
    "    ip_df = ip_df.sort_values('lower').reset_index(drop=True)\n",
    "\n",
    "    merged_df = pd.merge_asof(fraud_df, ip_df, left_on='ip_int', right_on='lower', direction='backward')\n",
    "\n",
    "    merged_df['purchase_time'] = pd.to_datetime(merged_df['purchase_time'], errors='coerce')\n",
    "    merged_df['signup_time'] = pd.to_datetime(merged_df['signup_time'], errors='coerce')\n",
    "\n",
    "    merged_df = merged_df.dropna(subset=['purchase_time', 'signup_time'])\n",
    "\n",
    "    merged_df['hour_of_day'] = merged_df['purchase_time'].dt.hour\n",
    "    merged_df['day_of_week'] = merged_df['purchase_time'].dt.dayofweek\n",
    "    merged_df['time_since_signup'] = (merged_df['purchase_time'] - merged_df['signup_time']).dt.total_seconds()\n",
    "\n",
    "    user_freq = merged_df.groupby('user_id').size().rename('user_transaction_count')\n",
    "    merged_df = merged_df.merge(user_freq, on='user_id')\n",
    "\n",
    "    # Encode categorical columns if any\n",
    "    cat_cols = merged_df.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        merged_df[col] = merged_df[col].astype('category').cat.codes\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def task1_prepare_creditcard_data(creditcard_path):\n",
    "    credit_df = pd.read_csv(\"../data/creditcard.csv\")\n",
    "    return credit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e394454-3f58-4faa-9cf7-6fdbf3730de1",
   "metadata": {},
   "source": [
    "# -------- Task 2: Model Building, Training & Evaluation --------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fd58900-5776-4e00-9d7c-f8570d41c22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fraud Detection Dataset =====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SMOTE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     55\u001b[39m X_cc = credit_df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Run models (Task 2)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43mrun_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_fraud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_fraud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFraud Detection Dataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m run_models(X_cc, y_cc, dataset_name=\u001b[33m\"\u001b[39m\u001b[33mCredit Card Dataset\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mrun_models\u001b[39m\u001b[34m(X, y, dataset_name)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_models\u001b[39m(X, y, dataset_name):\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m===== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m =====\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     X_train, X_test, y_train, y_test = \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mLogistic Regression Results:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m     lr = LogisticRegression(max_iter=\u001b[32m1000\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mprepare_data\u001b[39m\u001b[34m(X, y)\u001b[39m\n\u001b[32m      6\u001b[39m X_train_scaled = scaler.fit_transform(X_train)\n\u001b[32m      7\u001b[39m X_test_scaled = scaler.transform(X_test)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m smote = \u001b[43mSMOTE\u001b[49m(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     10\u001b[39m X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X_train_res, X_test_scaled, y_train_res, y_test\n",
      "\u001b[31mNameError\u001b[39m: name 'SMOTE' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def prepare_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    return X_train_res, X_test_scaled, y_train_res, y_test\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Average Precision (AUC-PR): {average_precision_score(y_test, y_proba):.4f}\")\n",
    "    print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "def run_models(X, y, dataset_name):\n",
    "    print(f\"\\n===== {dataset_name} =====\")\n",
    "    X_train, X_test, y_train, y_test = prepare_data(X, y)\n",
    "\n",
    "    print(\"\\nLogistic Regression Results:\")\n",
    "    lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    lr.fit(X_train, y_train)\n",
    "    evaluate_model(lr, X_test, y_test)\n",
    "\n",
    "    print(\"\\nRandom Forest Results:\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    evaluate_model(rf, X_test, y_test)\n",
    "\n",
    "# -------- Main --------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fraud_data_path = '../data/Fraud_Data.csv'\n",
    "    ip_data_path = '../data/IpAddress_to_Country.csv'\n",
    "    creditcard_data_path = '../data/creditcard.csv'\n",
    "\n",
    "    # Prepare datasets (Task 1)\n",
    "    merged_df = task1_prepare_fraud_data(fraud_data_path, ip_data_path)\n",
    "    credit_df = task1_prepare_creditcard_data(creditcard_data_path)\n",
    "\n",
    "    # Prepare features and targets for Task 2\n",
    "    y_fraud = merged_df['class']\n",
    "    X_fraud = merged_df.drop(columns=['class', 'signup_time', 'purchase_time', 'ip_address', 'ip_int'])\n",
    "\n",
    "    y_cc = credit_df['Class']\n",
    "    X_cc = credit_df.drop(columns=['Class'])\n",
    "\n",
    "    # Run models (Task 2)\n",
    "    run_models(X_fraud, y_fraud, dataset_name=\"Fraud Detection Dataset\")\n",
    "    run_models(X_cc, y_cc, dataset_name=\"Credit Card Dataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a2cf1-2892-4dab-b017-3b454728970a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
